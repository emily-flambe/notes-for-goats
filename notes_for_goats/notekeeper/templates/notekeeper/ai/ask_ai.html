{% extends "notekeeper/base.html" %}

{% block title %}Ask AI - {{ workspace.name }}{% endblock %}

{% block content %}
<div class="container mt-4">
    <div class="d-flex justify-content-between align-items-center mb-4">
        <h1>Ask AI</h1>
        <p>Ask the AI to answer questions and (optionally) save the response as a note.</p>
    </div>
    
    <div class="card shadow-sm mb-4">
        <div class="card-body">
            <!-- LLM Toggle with fixed width and no-wrap -->
            <form method="POST" id="toggle-form" class="mb-3">
                {% csrf_token %}
                <input type="hidden" name="toggle_llm" value="1">
                
                <div style="margin-bottom: 12px; width: 100%;">
                    <label style="display: inline-flex; align-items: center; cursor: pointer; white-space: nowrap;">
                        <input type="checkbox" 
                               id="useLocalLLM" 
                               name="use_local_llm" 
                               style="margin-right: 8px;" 
                               {% if use_local_llm %}checked{% endif %} 
                               onchange="document.getElementById('toggle-form').submit();">
                        <span style="white-space: nowrap;">Use local LLM</span>
                    </label>
                    
                    <div style="margin-left: 24px; margin-top: 4px;">
                        {% if use_local_llm %}
                            <small class="text-success">
                                <i class="bi bi-hdd-fill me-1"></i>
                                Using local model: {{ local_llm_model }}
                            </small>
                        {% else %}
                            <small class="text-primary">
                                <i class="bi bi-cloud-fill me-1"></i>
                                Using OpenAI API: {{ openai_model }}
                                {% if not has_openai_key %}
                                    <span class="text-danger ms-2">
                                        <i class="bi bi-exclamation-triangle-fill"></i>
                                        API key not configured
                                    </span>
                                {% endif %}
                            </small>
                        {% endif %}
                    </div>
                </div>
            </form>
            
            <!-- Add this right after the LLM toggle form -->
            <form method="POST" id="direct-prompt-form" class="mb-3">
                {% csrf_token %}
                <input type="hidden" name="toggle_direct_prompt" value="1">
                
                <div style="margin-bottom: 12px; width: 100%;">
                    <label style="display: inline-flex; align-items: center; cursor: pointer; white-space: nowrap;">
                        <input type="checkbox" 
                               id="useDirectPrompt" 
                               name="use_direct_prompt" 
                               style="margin-right: 8px;" 
                               {% if use_direct_prompt %}checked{% endif %} 
                               onchange="document.getElementById('direct-prompt-form').submit();">
                        <span style="white-space: nowrap;">Direct prompt (no context)</span>
                    </label>
                    
                    <div style="margin-left: 24px; margin-top: 4px;">
                        {% if use_direct_prompt %}
                            <small class="text-warning">
                                <i class="bi bi-exclamation-triangle-fill me-1"></i>
                                Using direct prompt mode: No app context or special instructions will be added.
                            </small>
                        {% else %}
                            <small class="text-info">
                                <i class="bi bi-info-circle-fill me-1"></i>
                                Using enhanced mode: App context and instructions will be added.
                            </small>
                        {% endif %}
                    </div>
                </div>
            </form>
            
            <!-- AI Question Form -->
            <form method="POST" id="ai-form">
                {% csrf_token %}
                <div class="form-group">
                    <label for="user_query">Your Question:</label>
                    <textarea name="user_query" id="user_query" class="form-control" rows="3" 
                        placeholder="{% if use_direct_prompt %}Enter your prompt exactly as you want to send it to the AI...{% else %}E.g., Summarize my notes about Project X or What did I discuss with Alice last week?{% endif %}" required></textarea>
                </div>
                <button type="submit" class="btn btn-primary mt-3" id="submit-btn">
                    <i class="bi bi-robot me-1"></i> Ask AI
                </button>
            </form>
        </div>
    </div>
    
    <div id="loading" class="text-center my-4" style="display: none;">
        <div class="spinner-border text-primary" role="status">
            <span class="visually-hidden">Loading...</span>
        </div>
        <p class="mt-2">
            {% if use_local_llm %}
                Processing with local model (this may take longer, please be patient)...
            {% else %}
                Asking OpenAI...
            {% endif %}
        </p>
    </div>
    
    {% if ai_response %}
    <div class="card shadow-sm" id="response-card">
        <div class="card-header bg-light d-flex justify-content-between align-items-center">
            <h5 class="mb-0">AI Response</h5>
            <div>
                <span class="badge {% if use_direct_prompt %}bg-warning{% else %}bg-info{% endif %} me-2">
                    {% if use_direct_prompt %}Direct Prompt{% else %}Enhanced Mode{% endif %}
                </span>
                <span class="badge {% if use_local_llm %}bg-success{% else %}bg-primary{% endif %}">
                    {% if use_local_llm %}Local LLM{% else %}OpenAI{% endif %}
                </span>
            </div>
        </div>
        
        <!-- Only display token info if it exists -->
        {% if token_info %}
        <div class="token-info-alert alert {% if token_info.total > token_info.limit_threshold %}alert-warning{% else %}alert-info{% endif %} m-3 mb-0">
            <div class="d-flex align-items-center">
                <i class="bi {% if token_info.total > token_info.limit_threshold %}bi-exclamation-triangle{% else %}bi-info-circle{% endif %} me-2"></i>
                <div>
                    <strong>Token Usage:</strong> {{ token_info.total|floatformat:0 }} / {{ token_info.limit }} tokens
                    ({% widthratio token_info.total token_info.limit 100 %}%)
                    
                    {% if token_info.use_rag %}
                    <br>
                    <small>
                        <span class="badge bg-success">RAG Active</span>
                        Using semantic search to find relevant content ({{ token_info.context|floatformat:0 }} tokens)
                    </small>
                    {% endif %}
                    
                    {% if token_info.total > token_info.limit_threshold %}
                    <br>
                    <small class="text-warning">
                        <i class="bi bi-exclamation-triangle-fill"></i>
                        Approaching token limit - consider using more specific questions or direct prompt mode.
                    </small>
                    {% endif %}
                </div>
            </div>
        </div>
        {% endif %}
        
        <div class="card-body">
            <!-- User's prompt displayed in bold -->
            <div class="user-prompt mb-3">
                <strong>Your question:</strong>
                <div class="prompt-text p-2 border-start border-4 border-primary bg-light">
                    {{ user_query }}
                </div>
            </div>
            
            <div class="ai-model-info mb-2">
                <strong>Model used:</strong> 
                <span class="model-name">{% if use_local_llm %}{{ local_llm_model }}{% else %}{{ openai_model }}{% endif %}</span>
            </div>
            
            <div class="ai-response">{{ ai_response|linebreaks }}</div>
        </div>
        <div class="card-footer bg-light d-flex justify-content-between">
            <button class="btn btn-sm btn-outline-secondary" onclick="copyToClipboard()">
                <i class="bi bi-clipboard"></i> Copy Response
            </button>
            <form method="POST" action="{% url 'notekeeper:save_ai_chat' workspace_id=workspace.id %}">
                {% csrf_token %}
                <input type="hidden" name="title" value="{{ user_query|truncatechars:50|striptags|safe }}" />
                <input type="hidden" name="content" id="note-content" />
                <button type="submit" class="btn btn-sm btn-primary" onclick="prepareContent()">
                    <i class="bi bi-journal-plus"></i> Save as Note
                </button>
            </form>
        </div>
    </div>
    {% endif %}
</div>

<style>
/* Additional CSS to ensure the toggle displays properly */
#toggle-form {
    width: 100%;
}

/* Styling for the prompt display */
.prompt-text {
    font-weight: 500;
    margin-top: 5px;
    border-radius: 0.25rem;
}

/* Token info styling */
.token-info-alert {
    font-size: 0.9rem;
    padding: 0.5rem 1rem;
}
</style>

<script>
    // Add function to prepare content for saving as a note
    function prepareContent() {
        const formattedContent = `**Question:** ${document.querySelector('.prompt-text').innerText.trim()}

**Model:** ${document.querySelector('.model-name').innerText.trim()}

**Response:**
${document.querySelector('.ai-response').innerText.trim()}`;
        
        document.getElementById('note-content').value = formattedContent;
    }
    
    // Show loading indicator when form is submitted
    document.getElementById('ai-form').addEventListener('submit', function() {
        document.getElementById('loading').style.display = 'block';
        document.getElementById('submit-btn').disabled = true;
        document.getElementById('submit-btn').innerHTML = '<span class="spinner-border spinner-border-sm" role="status" aria-hidden="true"></span> Processing...';
    });
    
    // Function to copy response to clipboard
    function copyToClipboard() {
        const responseEl = document.querySelector('.ai-response');
        const text = responseEl.innerText;
        
        navigator.clipboard.writeText(text).then(function() {
            alert('Response copied to clipboard!');
        }, function(err) {
            console.error('Could not copy text: ', err);
        });
    }
</script>
{% endblock %}
